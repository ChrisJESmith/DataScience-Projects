{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Credit Risk for Lending Club\n",
    "\n",
    "We will explore the full data science life cycle, from data cleaning and feature selection to machine learning. We will focus on credit modelling, that focuses on modeling a borrower's credit risk. \n",
    "\n",
    "We will work with financial lending data from Lending Club, a marketplace for personal loans that matches borrowers who are seeking a loan with investors looking to lend money and make a return.\n",
    "\n",
    "Each borrower fills out an application, providing their past financial history, the reason for the loan etc. Lending Club evaluates each borrower's credit score using past historical data (and their own data science process) and assign an interest rate to the borrower. A higher interest rate means the borrower is riskier, and more unlikely to pay back the loan, while a lower interest rate means the borrower has a good credit history and more likely to pay back the loan. The interest rates range from 5.32% all the way to 30.99% and each borrower is given a grade according to the interest rate they were assigned. If the borrower accepts the interest rate, then the loan is listed on the Lending Club marketplace.\n",
    "\n",
    "Approved loans are listed on the website, where investors can browse recently approved loans, the borrower's credit score, the purpose for the loan etc. Once they're ready to back a loan, they select the amount of money they want to fund. Once a loan's requested amount is fully funded, the borrower receives the money they requested minus the origination fee that Lending Club charges.\n",
    "\n",
    "The borrower then makes monthly payments back to Lending Club either over 36 months or over 60 months. Lending Club redistributes these payments to the investors. Many loans aren't completely paid off on time, however, and some borrowers default on the loan.\n",
    "\n",
    "In this project, we will focus on the mindset of a conservative investor, who only wants to invest in loans that have a good chance of being paid off on time. To do that, we need to first understand the features in the dataset, and then experiment with building machine learning models that reliably predict if a loan will be paid off or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Dataset\n",
    "\n",
    "The approved loans datasets contain information on current loans, completed loans, and defaulted loans. We will define the problem statement for this machine learning project:\n",
    "\n",
    "- can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\n",
    "\n",
    "We first need to define what features we want to use, and which column repesents the target column we want to predict. We will read in the data and explore it.\n",
    "\n",
    "We will focus on approved loans data from 2007 to 2011, since a good number of the loans have already finished. In the datasets for later years, many of the loans are current, and still being paid off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans_2007 = pd.read_csv(r\"C:\\projectdatasets\\loans_2007.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                1077501\n",
      "member_id                      1.2966e+06\n",
      "loan_amnt                            5000\n",
      "funded_amnt                          5000\n",
      "funded_amnt_inv                      4975\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "grade                                   B\n",
      "sub_grade                              B2\n",
      "emp_title                             NaN\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "issue_d                            Dec-11\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "zip_code                            860xx\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                   Jan-85\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                         83.70%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "out_prncp                               0\n",
      "out_prncp_inv                           0\n",
      "total_pymnt                       5863.16\n",
      "total_pymnt_inv                   5833.84\n",
      "total_rec_prncp                      5000\n",
      "total_rec_int                      863.16\n",
      "total_rec_late_fee                      0\n",
      "recoveries                              0\n",
      "collection_recovery_fee                 0\n",
      "last_pymnt_d                       Jan-15\n",
      "last_pymnt_amnt                    171.62\n",
      "last_credit_pull_d                 Jun-16\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# show the first record\n",
    "print(loans_2007.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# show the number of columns\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42538\n"
     ]
    }
   ],
   "source": [
    "# show the number of rows\n",
    "print(loans_2007.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Unnecessary Columns\n",
    "\n",
    "There are many columns that are cumbersometo explore all at once. Pay attention to any features that:\n",
    "\n",
    "- leak information from the future (after the loan has already been funded)\n",
    "- don't affect a borrower's ability to pay back a loan (e.g. a randomly -generated ID value)\n",
    "- formatted poorly and requires cleaning\n",
    "- require more data, or more processing to turn into a useful feature\n",
    "- contain redundant information\n",
    "\n",
    "We need to pay attention to data leakage, since it can cause our model to overfit. This is because the model would be using data about the target column that wouldn't be available when using the model on future loans. We need to select one of the columns as the target column to use, for the machine learning phase. We can conclude the following features need to be removed:\n",
    "\n",
    "- id: randomly generated field for unique identification purposes only\n",
    "- member_id: randomly generated field for unique identification purposes only\n",
    "- funded_amnt: leaks data from the future (after loan starts to be funded)\n",
    "- funded_amnt_inv: same as above\n",
    "- grade: contains redundant information as the interest rate column (int_rate)\n",
    "- sub_grade: same above\n",
    "- emp_title: requires other data and lots of processing to be useful\n",
    "- issue_d: leaks data from the future (after loan is completed funded)\n",
    "\n",
    "Lending Club assigns a grade and a sub-grade based on the borrower's interest rate. While the grade and sub_grade values are categorical, the 'int_rate' column contains continuous values, which are better suited for machine learning.\n",
    "\n",
    "We will drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"id\", \"member_id\", \"funded_amnt\", \n",
    "                              \"funded_amnt_inv\", \"grade\", \"sub_grade\", \n",
    "                              \"emp_title\", \"issue_d\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also drop the following columns:\n",
    "\n",
    "- zip_code: redundant with the addr_state column since only the first 3 digits of the 5 digit zip code are visible\n",
    "- out_prncp: leaks data from the future (after loan is being paid off)\n",
    "- out_prncp_inv: same as above\n",
    "- total_pymnt: same as above\n",
    "- total_pymnt_inv: same as above\n",
    "- total_rec_prncp: same as above\n",
    "\n",
    "The 'out_prncp' and 'out_prncp_inv' both describe the outstanding principal amount for a loan. These 2 columns, as well as the 'total_pymnt' column describe properties of the loan after it's fully funded and started to be paid off. This information isn't available to an investor before the loan is fully funded,  so we don't want to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"zip_code\", \"out_prncp\", \"out_prncp_inv\", \n",
    "                              \"total_pymnt\", \"total_pymnt_inv\", \n",
    "                              \"total_rec_prncp\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to drop the following columns:\n",
    "\n",
    "- total_rec_int: leaks data from the future (after loan is being paid off)\n",
    "- total_rec_late_fee: same as above\n",
    "- recoveries: same as above\n",
    "- collection_recovery_fee: same as above\n",
    "- last_pymnt_d: same as above\n",
    "- last_pymnt_amnt: same as above\n",
    "\n",
    "All these columns leak data from the future, meaning that they're describing aspects of the loan after it's already been fully funded and started to be paid off by the borrower. This information isn't available to an investor before the loan is fully funded, so we don't want to include it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_2007 = loans_2007.drop([\"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \n",
    "                              \"collection_recovery_fee\", \n",
    "                              \"last_pymnt_d\", \"last_pymnt_amnt\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                            5000\n",
      "term                            36 months\n",
      "int_rate                           10.65%\n",
      "installment                        162.87\n",
      "emp_length                      10+ years\n",
      "home_ownership                       RENT\n",
      "annual_inc                          24000\n",
      "verification_status              Verified\n",
      "loan_status                    Fully Paid\n",
      "pymnt_plan                              n\n",
      "purpose                       credit_card\n",
      "title                            Computer\n",
      "addr_state                             AZ\n",
      "dti                                 27.65\n",
      "delinq_2yrs                             0\n",
      "earliest_cr_line                   Jan-85\n",
      "inq_last_6mths                          1\n",
      "open_acc                                3\n",
      "pub_rec                                 0\n",
      "revol_bal                           13648\n",
      "revol_util                         83.70%\n",
      "total_acc                               9\n",
      "initial_list_status                     f\n",
      "last_credit_pull_d                 Jun-16\n",
      "collections_12_mths_ex_med              0\n",
      "policy_code                             1\n",
      "application_type               INDIVIDUAL\n",
      "acc_now_delinq                          0\n",
      "chargeoff_within_12_mths                0\n",
      "delinq_amnt                             0\n",
      "pub_rec_bankruptcies                    0\n",
      "tax_liens                               0\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# display the first row\n",
    "print(loans_2007.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# show the number of columns (now a reduced number)\n",
    "print(loans_2007.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Target Column\n",
    "\n",
    "We have reduced the columns from 52 to 32. We now need to decide on a target column to use for modeling.\n",
    "\n",
    "We should use the 'loan_status' column, since it's the only column that directly describes if a loan was paid off on time, had delayed payments, or was defaulted on the borrower. Currently, this column contains text values, and we need to convert it to a numerical one for training a model. \n",
    "\n",
    "We will explore the different values in this column, and come up with a strategy for converting the values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             33136\n",
      "Charged Off                                             5634\n",
      "Does not meet the credit policy. Status:Fully Paid      1988\n",
      "Current                                                  961\n",
      "Does not meet the credit policy. Status:Charged Off      761\n",
      "Late (31-120 days)                                        24\n",
      "In Grace Period                                           20\n",
      "Late (16-30 days)                                          8\n",
      "Default                                                    3\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans_2007['loan_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation for each column:\n",
    "\n",
    "- Fully Paid - loan fully paid off\n",
    "- Charged Off - loan for which there is no longer a reasonable expectation of further payments\n",
    "- Does not meet the credit policy. Status:Fully Paid - while the loan was paid off, the loan application today would no longer meet the credit policy and wouldn't be approved\n",
    "- Does not meet the credit policy. Status:Charged Off - while the loan was charged off, the loan application today would no longer meet the credit policy and wouldn't be approved\n",
    "- In Grace Period - loan is past due but still in the grace period of 15 days\n",
    "- Late (16-30 days) - loan hasn't been paid in 16 to 30 days (late on the current payment)\n",
    "- Late (31-120 days) - loan hasn't been paid in 31 to 120 days (late on the current payment)\n",
    "- Current - loan is up to date on current payments\n",
    "- Default - loan is defaulted, and no payment has been made for more than 121 days\n",
    "\n",
    "From the investor's perspective, we want to predict which loans will be paid off on time, and which ones won't be. Only the 'Fully Paid' and 'Charged Off' values describe the final outcome of the loan. While the 'Default' status resembles Charged Off, they have essentially no chance of being repaid, while default ones have a small chance.\n",
    "\n",
    "Since we're interested in predicting which of these 2 values a loan will fall under, we can treat the problem as a binary classification one. We will remove all loans that don't contain either 'Fully Paid' and 'Charged Off' as the loan's status, and then transform the 'Fully Paid' values to 1 for the positive case, and the 'Charged Off' values to 0 for the negative case. \n",
    "\n",
    "We can use the method 'replace' to transform column values, and we can pass the replace method a nested mapping dictionary in the following format:\n",
    "\n",
    "mapping_dict = {\n",
    "    \"date\": {\n",
    "        \"january\": 1,\n",
    "        \"february\": 2,\n",
    "        \"march\": 3\n",
    "    }\n",
    "}\n",
    "\n",
    "df = df.replace(mapping_dict)\n",
    "\n",
    "We also need to consider the 'class imbalance' between the positive and negative cases. While there are 33,136 loans that have been fully paid off, there are only 5,634 that were charged off. This class imbalance is a common problem in binary classification, and during training, the model ends up having a strong bias towards predicting the class with more observations in the training set, and will rarely predict the class with less observations. The stronger the imbalance, the more biased the model becomes. We will tackle the class imbalance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only loans that are 'Fully Paid' and 'Charged Off'\n",
    "loans_2007 = loans_2007[(loans_2007['loan_status'] == \"Fully Paid\") \n",
    "                        | (loans_2007['loan_status'] == \"Charged Off\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the mapping dictionary\n",
    "status_replace = {\n",
    "    \"loan_status\" : {\n",
    "        \"Fully Paid\": 1,\n",
    "        \"Charged Off\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "# replace the values with the mapping dictionary\n",
    "loans_2007 = loans_2007.replace(status_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>...</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Jun-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>RENT</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Sep-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>12252.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Jun-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>49200.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.90%</td>\n",
       "      <td>156.46</td>\n",
       "      <td>3 years</td>\n",
       "      <td>RENT</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>Jan-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term int_rate  installment emp_length home_ownership  \\\n",
       "0     5000.0   36 months   10.65%       162.87  10+ years           RENT   \n",
       "1     2500.0   60 months   15.27%        59.83   < 1 year           RENT   \n",
       "2     2400.0   36 months   15.96%        84.33  10+ years           RENT   \n",
       "3    10000.0   36 months   13.49%       339.31  10+ years           RENT   \n",
       "5     5000.0   36 months    7.90%       156.46    3 years           RENT   \n",
       "\n",
       "   annual_inc verification_status  loan_status pymnt_plan    ...      \\\n",
       "0     24000.0            Verified            1          n    ...       \n",
       "1     30000.0     Source Verified            0          n    ...       \n",
       "2     12252.0        Not Verified            1          n    ...       \n",
       "3     49200.0     Source Verified            1          n    ...       \n",
       "5     36000.0     Source Verified            1          n    ...       \n",
       "\n",
       "  initial_list_status last_credit_pull_d collections_12_mths_ex_med  \\\n",
       "0                   f             Jun-16                        0.0   \n",
       "1                   f             Sep-13                        0.0   \n",
       "2                   f             Jun-16                        0.0   \n",
       "3                   f             Apr-16                        0.0   \n",
       "5                   f             Jan-16                        0.0   \n",
       "\n",
       "   policy_code  application_type acc_now_delinq  chargeoff_within_12_mths  \\\n",
       "0          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "1          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "2          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "3          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "5          1.0        INDIVIDUAL            0.0                       0.0   \n",
       "\n",
       "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
       "0          0.0                   0.0        0.0  \n",
       "1          0.0                   0.0        0.0  \n",
       "2          0.0                   0.0        0.0  \n",
       "3          0.0                   0.0        0.0  \n",
       "5          0.0                   0.0        0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the 'loan_status' column which is now 0s and 1s\n",
    "loans_2007.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at any columns that contain only one unique value, and remove them. These columns won't be useful for the model, since they don't add any information to each loan application.\n",
    "\n",
    "We will compute the number of unique values in each column, and drop the columns that contain only one unique value. First we should drop the null values, then compute the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_columns = loans_2007.columns\n",
    "drop_columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in orig_columns:\n",
    "    # drop null values in each column, and return the unique values\n",
    "    col_series = loans_2007[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "\n",
    "# drop columns that have only 1 unique value\n",
    "loans_2007 = loans_2007.drop(drop_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing The Features\n",
    "\n",
    "We have removed all columns that contained redundant information, weren't useful for modeling, required too much processing, or leaked information from the future. \n",
    "\n",
    "We will now prepare the data for machine learning by focusing on handling missing values, converting categorical columns to numeric columns, and removing any other extraneous columns. This is because the mathematics underlying most machine learning models assumes the data is numerical, and contains no missing values.\n",
    "\n",
    "We will compute the number of missing values. We can return the number of missing values by:\n",
    "\n",
    "- using the method 'isnull' to return a Dataframe containing Boolean values (True if value is null, False is value is not null)\n",
    "- then using the method 'sum 'to calculate the number of null values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans_2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt                  0\n",
      "term                       0\n",
      "int_rate                   0\n",
      "installment                0\n",
      "emp_length              1036\n",
      "home_ownership             0\n",
      "annual_inc                 0\n",
      "verification_status        0\n",
      "loan_status                0\n",
      "purpose                    0\n",
      "title                     11\n",
      "addr_state                 0\n",
      "dti                        0\n",
      "delinq_2yrs                0\n",
      "earliest_cr_line           0\n",
      "inq_last_6mths             0\n",
      "open_acc                   0\n",
      "pub_rec                    0\n",
      "revol_bal                  0\n",
      "revol_util                50\n",
      "total_acc                  0\n",
      "last_credit_pull_d         2\n",
      "pub_rec_bankruptcies     697\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show the number of null values for each column\n",
    "null_counts = loans.isnull().sum()\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns have 50 or less rows with missing values, and 1 column, ''pub_rec_bankruptcies', contains 697 rows with missing values.\n",
    "\n",
    "We will remove columns where more than 1% of the rows for that column contain a null value, and remove rows containing null values. So we will keep the following columns, and just remove rows containing missing values for them:\n",
    "\n",
    "- title\n",
    "- revol_util\n",
    "- last_credit_pull_d\n",
    "\n",
    "We will drop the 'pub_rec_bankruptcies' column entirely.\n",
    "\n",
    "We will use the strategy of removing the 'pub_rec_bankruptcies' column first, then removing all rows containing any missing values. This way, we only remove the rows containing missing values for the 'title' and 'revol_util' columns but not the 'pub_rec_bankruptcies' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     11\n",
      "float64    10\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# drop the 'pub_rec_bankruptcies' COLUMN (axis = 1)\n",
    "loans = loans.drop(\"pub_rec_bankruptcies\", axis=1)\n",
    "\n",
    "# drop ROWS (axis = 0) with missing values\n",
    "loans = loans.dropna(axis=0)\n",
    "\n",
    "# return the counts showing the numbers of each column per data type\n",
    "print(loans.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object columns that contain text need to be converted to numerical data.  We will select just the object columns, then display a sample row to get a better sense of how the values in each column are formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                     36 months\n",
      "int_rate                    10.65%\n",
      "emp_length               10+ years\n",
      "home_ownership                RENT\n",
      "verification_status       Verified\n",
      "purpose                credit_card\n",
      "title                     Computer\n",
      "addr_state                      AZ\n",
      "earliest_cr_line            Jan-85\n",
      "revol_util                  83.70%\n",
      "last_credit_pull_d          Jun-16\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# filter by the object/text columns\n",
    "object_columns_df = loans.select_dtypes(include=[\"object\"])\n",
    "\n",
    "# show the first row\n",
    "print(object_columns_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns represent categorical values, but we should confirm by checking the number of unique values in those columns:\n",
    "\n",
    "- home_ownership: home ownership status, can only be 1 of 4 categorical values\n",
    "- verification_status: indicates if income was verified by Lending Club\n",
    "- emp_length: number of years the borrower has been employed\n",
    "- term: number of payments on the loan, either 36 or 60\n",
    "- addr_state: borrower's state of residence\n",
    "- purpose: a category provided by the borrower for the loan request\n",
    "- title: loan title provided the borrower\n",
    "\n",
    "There are some columns that represent numeric values, that need to be converted:\n",
    "\n",
    "- int_rate: interest rate of the loan in %\n",
    "- revol_util: revolving line utilisation rate, or the amount of credit the borrower is using relative to all available credit\n",
    "\n",
    "Based on the first row's values for 'purpose' and 'title', it seems like these columns could reflect the same information. Let's explore the unique value counts separately to confirm this.\n",
    "\n",
    "Lastly, some of the columns contain date values that would require feature engineering to be potentially useful:\n",
    "\n",
    "- earliest_cr_line: the month the borrower's earliest credit line was opened\n",
    "- last_credit_pull_d: the most recent month Lending Club pulled credit for this loan\n",
    "\n",
    "Since these date features require feature engineering for modeling purposes, we will remove these date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RENT        18112\n",
      "MORTGAGE    16686\n",
      "OWN          2778\n",
      "OTHER          96\n",
      "NONE            3\n",
      "Name: home_ownership, dtype: int64\n",
      "Not Verified       16281\n",
      "Verified           11856\n",
      "Source Verified     9538\n",
      "Name: verification_status, dtype: int64\n",
      "10+ years    8545\n",
      "< 1 year     4513\n",
      "2 years      4303\n",
      "3 years      4022\n",
      "4 years      3353\n",
      "5 years      3202\n",
      "1 year       3176\n",
      "6 years      2177\n",
      "7 years      1714\n",
      "8 years      1442\n",
      "9 years      1228\n",
      "Name: emp_length, dtype: int64\n",
      " 36 months    28234\n",
      " 60 months     9441\n",
      "Name: term, dtype: int64\n",
      "CA    6776\n",
      "NY    3614\n",
      "FL    2704\n",
      "TX    2613\n",
      "NJ    1776\n",
      "IL    1447\n",
      "PA    1442\n",
      "VA    1347\n",
      "GA    1323\n",
      "MA    1272\n",
      "OH    1149\n",
      "MD    1008\n",
      "AZ     807\n",
      "WA     788\n",
      "CO     748\n",
      "NC     729\n",
      "CT     711\n",
      "MI     678\n",
      "MO     648\n",
      "MN     581\n",
      "NV     466\n",
      "SC     454\n",
      "WI     427\n",
      "OR     422\n",
      "AL     420\n",
      "LA     420\n",
      "KY     311\n",
      "OK     285\n",
      "UT     249\n",
      "KS     249\n",
      "AR     229\n",
      "DC     209\n",
      "RI     194\n",
      "NM     180\n",
      "WV     164\n",
      "HI     162\n",
      "NH     157\n",
      "DE     110\n",
      "MT      77\n",
      "AK      76\n",
      "WY      76\n",
      "SD      60\n",
      "VT      53\n",
      "MS      19\n",
      "TN      17\n",
      "IN       9\n",
      "ID       6\n",
      "IA       5\n",
      "NE       5\n",
      "ME       3\n",
      "Name: addr_state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# look at unique value counts of the columnns containing categorical values\n",
    "cols = ['home_ownership', 'verification_status', \n",
    "        'emp_length', 'term', 'addr_state']\n",
    "for c in cols:\n",
    "    print(loans[c].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'home_ownership', 'verification_status', 'emp_length', 'term', and 'addr_state' columns all contain multiple discrete values. \n",
    "\n",
    "We should clean the 'emp_length' column and treat it as numerical, since the values have ordering (i.e. 2 years of employment is less than 8 years).\n",
    "\n",
    "We will look at the unique value counts for the purpose and title columns to understand which column we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debt_consolidation    17751\n",
      "credit_card            4911\n",
      "other                  3711\n",
      "home_improvement       2808\n",
      "major_purchase         2083\n",
      "small_business         1719\n",
      "car                    1459\n",
      "wedding                 916\n",
      "medical                 655\n",
      "moving                  552\n",
      "house                   356\n",
      "vacation                348\n",
      "educational             312\n",
      "renewable_energy         94\n",
      "Name: purpose, dtype: int64\n",
      "Debt Consolidation                                                       2068\n",
      "Debt Consolidation Loan                                                  1599\n",
      "Personal Loan                                                             624\n",
      "Consolidation                                                             488\n",
      "debt consolidation                                                        466\n",
      "Credit Card Consolidation                                                 345\n",
      "Home Improvement                                                          336\n",
      "Debt consolidation                                                        314\n",
      "Small Business Loan                                                       298\n",
      "Credit Card Loan                                                          294\n",
      "Personal                                                                  290\n",
      "Consolidation Loan                                                        250\n",
      "Home Improvement Loan                                                     228\n",
      "personal loan                                                             219\n",
      "Loan                                                                      202\n",
      "Wedding Loan                                                              199\n",
      "personal                                                                  198\n",
      "Car Loan                                                                  188\n",
      "consolidation                                                             186\n",
      "Other Loan                                                                168\n",
      "Wedding                                                                   148\n",
      "Credit Card Payoff                                                        144\n",
      "Credit Card Refinance                                                     140\n",
      "Major Purchase Loan                                                       131\n",
      "Consolidate                                                               124\n",
      "Medical                                                                   111\n",
      "Credit Card                                                               110\n",
      "home improvement                                                          101\n",
      "Credit Cards                                                               91\n",
      "My Loan                                                                    90\n",
      "                                                                         ... \n",
      "Family07                                                                    1\n",
      "payoff CAPITAL ONE!                                                         1\n",
      "bermuda                                                                     1\n",
      "Get rid of CCs & house                                                      1\n",
      "homerdude                                                                   1\n",
      "Mortgage Pre-Payment                                                        1\n",
      "Secondhand car purchase w/o using cash                                      1\n",
      "JE and Debt                                                                 1\n",
      "siding                                                                      1\n",
      "For Continuing Education                                                    1\n",
      "spending money to save money                                                1\n",
      "CPA exam costs                                                              1\n",
      "Help with a vehicle                                                         1\n",
      "Flipflop Girl Wants To Be Debt-Free!!                                       1\n",
      "Economy Restructuring                                                       1\n",
      "used harley                                                                 1\n",
      "790+ FICO Score Looking For Loan                                            1\n",
      "Retainer                                                                    1\n",
      "d.everett SOS",
      "Hail Mary Time! Double-down & we can score the WIN-WIN!       1\n",
      "The Austin Photography Group                                                1\n",
      "Help me refi my credit card                                                 1\n",
      "Home Improvement - Vinyl Siding                                             1\n",
      "Help Me Make You Money                                                      1\n",
      "FranksHelp                                                                  1\n",
      "update kitchen                                                              1\n",
      "Payoff my Credit Card Debit in 36 Months                                    1\n",
      "Need a new roof                                                             1\n",
      "pay off 2 bills                                                             1\n",
      "Nissan Car Loan                                                             1\n",
      "Wedding expense                                                             1\n",
      "Name: title, Length: 18871, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans[\"purpose\"].value_counts())\n",
    "print(loans[\"title\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'home_ownership', 'verification_status', 'emp_length', and 'term' columns each contain some discrete categorical values. We should encode these columns as dummy variables and keep them.\n",
    "\n",
    "The 'purpose' and 'title' columns do contain overlapping information, but we'll keep the 'purpose' column since it contains a few discrete values. In addition, the 'title' column has data quality issues since many of the values are repeated with slight modifications (e.g. Debt Consolidation and Debt Consolidation Loan and debt consolidation).\n",
    "\n",
    "We will use the a mapping to clean the emp_length column.\n",
    "\n",
    "Lastly, the 'addr_state' column contains many discrete values, and we'd need to add 49 dummy variable columns to use it for classification. This would make our Dataframe much larger, and could slow down how quickly the code runs. So we will remove this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to clean the 'emp_length' column\n",
    "mapping_dict = {\n",
    "    \"emp_length\": {\n",
    "        \"10+ years\": 10,\n",
    "        \"9 years\": 9,\n",
    "        \"8 years\": 8,\n",
    "        \"7 years\": 7,\n",
    "        \"6 years\": 6,\n",
    "        \"5 years\": 5,\n",
    "        \"4 years\": 4,\n",
    "        \"3 years\": 3,\n",
    "        \"2 years\": 2,\n",
    "        \"1 year\": 1,\n",
    "        \"< 1 year\": 0,\n",
    "        \"n/a\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the following columns\n",
    "loans = loans.drop([\"last_credit_pull_d\", \"earliest_cr_line\", \n",
    "                    \"addr_state\", \"title\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'int_rate' and 'revol_util' columns to float columns\n",
    "    # strip the right trailing percent sign (%) using 'str.rstrip'\n",
    "    # then use 'astype' to convert to float\n",
    "\n",
    "loans[\"int_rate\"] = loans[\"int_rate\"].str.rstrip(\"%\").astype(\"float\")\n",
    "loans[\"revol_util\"] = loans[\"revol_util\"].str.rstrip(\"%\").astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 'replace' method to clean the 'emp_length' column using dictionary above\n",
    "loans = loans.replace(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1     0\n",
       "2    10\n",
       "3    10\n",
       "5     3\n",
       "Name: emp_length, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the cleansed 'emp_length' field\n",
    "loans[\"emp_length\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now encode the 'home_ownership', 'verification_status', 'purpose', and 'term' columns as dummy variables, to use them in our model: \n",
    "\n",
    "- firstly, use the Pandas 'get_dummies' method to return a new Dataframe containing a new column for each dummy variable.\n",
    "- secondly, use the 'concat' method to add these dummy columns back to the original Dataframe.\n",
    "- thirdly, drop the original columns entirely using the drop method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = [\"home_ownership\", \"verification_status\", \"purpose\", \"term\"]\n",
    "\n",
    "# return new dataframe containing new columns for each dummy variable\n",
    "dummy_df = pd.get_dummies(loans[cat_columns])\n",
    "\n",
    "# add these dummy columns back to original dataframe\n",
    "loans = pd.concat([loans, dummy_df], axis=1)\n",
    "\n",
    "# drop original columns\n",
    "loans = loans.drop(cat_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will experiment with training models, and evaluate accuracy using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "We have cleansed and prepared a dataset that contains data on loans made to members of Lending Club. We want to generate features from the data, which can feed into a machine learning algorithm. The algorithm will make predictions about whether or not a loan will be paid off on time, which is contained in the 'loan_status' column.\n",
    "\n",
    "So far, we have prepared the data, removed columns that had data leakage issues, contained redundant information, or required additional processing. We also cleaned features that had formatting issues, and converted categorical columns to dummy variables.\n",
    "\n",
    "We noticed a class imbalance in our target column, 'loan_status'. There are about 6 times as many loans that were paid off on time (positive case, label of 1) than those that weren't (negative case, label of 0). Imbalances can cause issues with machine learning algorithms, where they appear to have high accuracy, but actually aren't learning from the training data. Because of its potential to cause issues, we need to keep the class imbalance in mind as we build machine learning models.\n",
    "\n",
    "We will view a summary of the work we've done (using a pre-cleansed dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38708 entries, 0 to 38707\n",
      "Data columns (total 38 columns):\n",
      "loan_amnt                              38708 non-null int64\n",
      "int_rate                               38708 non-null float64\n",
      "installment                            38708 non-null float64\n",
      "emp_length                             38708 non-null int64\n",
      "annual_inc                             38708 non-null float64\n",
      "loan_status                            38708 non-null int64\n",
      "dti                                    38708 non-null float64\n",
      "delinq_2yrs                            38708 non-null int64\n",
      "inq_last_6mths                         38708 non-null int64\n",
      "open_acc                               38708 non-null int64\n",
      "pub_rec                                38708 non-null int64\n",
      "revol_bal                              38708 non-null int64\n",
      "revol_util                             38708 non-null float64\n",
      "total_acc                              38708 non-null int64\n",
      "home_ownership_MORTGAGE                38708 non-null int64\n",
      "home_ownership_NONE                    38708 non-null int64\n",
      "home_ownership_OTHER                   38708 non-null int64\n",
      "home_ownership_OWN                     38708 non-null int64\n",
      "home_ownership_RENT                    38708 non-null int64\n",
      "verification_status_Not Verified       38708 non-null int64\n",
      "verification_status_Source Verified    38708 non-null int64\n",
      "verification_status_Verified           38708 non-null int64\n",
      "purpose_car                            38708 non-null int64\n",
      "purpose_credit_card                    38708 non-null int64\n",
      "purpose_debt_consolidation             38708 non-null int64\n",
      "purpose_educational                    38708 non-null int64\n",
      "purpose_home_improvement               38708 non-null int64\n",
      "purpose_house                          38708 non-null int64\n",
      "purpose_major_purchase                 38708 non-null int64\n",
      "purpose_medical                        38708 non-null int64\n",
      "purpose_moving                         38708 non-null int64\n",
      "purpose_other                          38708 non-null int64\n",
      "purpose_renewable_energy               38708 non-null int64\n",
      "purpose_small_business                 38708 non-null int64\n",
      "purpose_vacation                       38708 non-null int64\n",
      "purpose_wedding                        38708 non-null int64\n",
      "term_ 36 months                        38708 non-null int64\n",
      "term_ 60 months                        38708 non-null int64\n",
      "dtypes: float64(5), int64(33)\n",
      "memory usage: 11.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "loans = pd.read_csv(r\"C:\\projectdatasets\\cleaned_loans_2007.csv\")\n",
    "print(loans.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into predicting 'loan_status', we will explore the original question:\n",
    "- can we build a machine learning model that can accurately predict if a borrower will pay off their loan on time or not?\n",
    "\n",
    "This is a binary classification problem, and converted the 'loan_status' column to 0s and 1s as a result. Before selecting an algorithm, we should select an error metric.\n",
    "\n",
    "The error metric will determine when our model is performing well, and when it's performing poorly. We want to predict whether we should fund a loan. Our objective is to make money - we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money, or lose us money.\n",
    "\n",
    "In this case, we're concerned with 'false positives' and 'false negatives'. Both are misclassifications. With a false positive, we predict a loan will be paid off on time, but it actually isn't. This costs us money. With a false negative, we predict a loan won't be paid off on time, but it actually would be paid off on time. This loses us potential money, since we didn't fund a profitable loan.\n",
    "\n",
    "A conservative investor would want to minimize risk, and avoid false positives. They'd be more okay with missing out on opportunities (false negatives) than funding a risky loan (false positives).\n",
    "\n",
    "We will calculate false positives and true positives in Python.\n",
    "\n",
    "NOTE - THE BELOW IS SAMPLE CODE - DON'T RUN - NO 'PREDICTIONS' EXIST YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of false positives\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# number of true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# number of false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# number of true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a class imbalance in the 'loan_status' column. There are 6 times as many loans that were paid off on time (1), than loans that weren't paid off on time (0). This causes an issue when using accuracy as a metric. This is because due to the class imbalance, a classifier may predict 1 for every row, and despite a few being wrong (and losing us money), the model is still has high accuracy.\n",
    "\n",
    "So be aware of imbalanced classes in machine learning models, and adjust error metric accordingly. Here, we don't want to use accuracy, and should use metrics that tell us the number of false positives and false negatives. This means that we should optimize for:\n",
    "\n",
    "- high recall (true positive rate)\n",
    "- low fall-out (false positive rate)\n",
    "\n",
    "We can calculate true positive rate, and false positive rate, using the numbers of true positives, true negatives, false negatives, and false positives.\n",
    "\n",
    "- False Positive Rate (FPR) is the number of false positives divided by the number of false positives, plus the number of true negatives: fpr = fp / (fp + tn)\n",
    "\n",
    "    This means \"what percentage of my 1 predictions are incorrect?\", or \"what percentage of the loans that I fund would not be repaid?\"\n",
    "    \n",
    "\n",
    "- True Positive Rate (TPR) is the number of true positives divided by the number of true positives, plus the number of false negatives: tpr = tp / (tp + fn)\n",
    "\n",
    "    This means \"what percentage of all the possible 1 predictions am I making?\" or \"what percentage of loans that could be funded would I fund?\n",
    "\n",
    "NOTE - THE BELOW IS SAMPLE CODE - DON'T RUN - NO 'PREDICTIONS' EXIST YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "# predict all loans will be paid off on time\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "\n",
    "# false positives\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)    # this equals 1\n",
    "print(fpr)    # this equals 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both fpr and tpr were 1. This is because we predicted 1 for each row. This means that we correctly identified all the good loans (true positive rate), but we also incorrectly identified all the bad loans (false positive rate). Now that we've setup error metrics, we can make predictions using a machine learning algorithm.\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Our cleaned dataset contains 41 columns, and are either the int64 or the float64 data type. There aren't any null values. So we can now apply any machine learning algorithm to our dataset.\n",
    "\n",
    "Although we can build our own implementations of algorithms, it's easier and faster to use algorithms someone else has already written and tuned for high performance (so we will use the Scikit-learn library)\n",
    "\n",
    "A good first algorithm to apply to binary classification problems is logistic regression, because:\n",
    "\n",
    "- it's quick to train and we can iterate more quickly,\n",
    "- it's less prone to overfitting than more complex models like decision trees,\n",
    "- it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# create a list of columns\n",
    "cols = loans.columns\n",
    "\n",
    "# remove the predictor column 'loan_status'\n",
    "train_cols = cols.drop(\"loan_status\")\n",
    "\n",
    "# create new dataframe of just the training columns (minus 'loan_status')\n",
    "features = loans[train_cols]\n",
    "\n",
    "# create new series of just the target column ('loan_status')\n",
    "target = loans[\"loan_status\"]\n",
    "\n",
    "# fit a logistic regression and make predictions\n",
    "lr.fit(features, target)\n",
    "predictions = lr.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we generated predictions, those predictions were overfit, because we generated predictions using the same data we trained our model on. When we use this to evaluate error, we get an unrealistically high depiction of how accurate the algorithm is, because it already \"knows\" the correct answers.\n",
    "\n",
    "To get a realistic depiction, we will perform k-fold cross validation. Once we have cross validated predictions, we can compute the true positive rate, and false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# ensure 3-fold cross validation is performed\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989121566494424\n",
      "0.9967943009795192\n"
     ]
    }
   ],
   "source": [
    "# number of false positives\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# number of true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# number of false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# number of true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'fpr' and 'tpr' are what we'd expect, if the model was predicting all ones.\n",
    "\n",
    "Unfortunately, even through we're not using accuracy as an error metric, the classifier is, and isn't accounting for the imbalance in the classes. There are a few ways to get a classifier to correct for imbalanced classes:\n",
    "\n",
    "- use oversampling and undersampling, to ensure the classifier gets input that has a balanced number of each class\n",
    "- tell the classifier to penalise misclassifications of the less prevalent class more than the other class\n",
    "\n",
    "We will consider oversampling and undersampling first. They involve taking a sample that contains equal numbers of rows where 'loan_status' is 0, and where 'loan_status' is 1. This way, the classifier is forced to make actual predictions, since predicting all 1s or all 0s will only result in 50% accuracy at most. The downside of this, is that since it has to preserve an equal ratio, you have to either:\n",
    "\n",
    "- throw out many rows of data i.e. where 'loan_status' is 1.\n",
    "- copy rows i.e. copy rows where 'loan_status' is 0 to equalise the rows\n",
    "- generate fake data i.e. generate new rows where 'loan_status' is 0.\n",
    "\n",
    "None of these techniques are easy. \n",
    "\n",
    "The second method is telling the classifier to penalise certain rows more, which is easier to implement. We can do this by setting the 'class_weight' parameter to 'balanced' when creating the LogisticRegression instance. This tells it to penalise the misclassification of the minority class during training. So the logistic regression classifier pays more attention to correctly classifying rows where 'loan_status' is 0. This lowers accuracy when 'loan_status' is 1, but raises accuracy when 'loan_status' is 0.\n",
    "\n",
    "The penalty is set to be inversely proportional to the class frequencies. Correctly classifying a row where 'loan_status' is 0 is 6 times more important than correctly classifying a row where 'loan_status' is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# this time, set 'class_weight' to 'balanced'\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6644909799655516\n",
      "0.38913624220837045\n"
     ]
    }
   ],
   "source": [
    "# number of false positives\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# number of true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# number of false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# number of true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improved the false positive rate by balancing the classes, which reduced the true positive rate. Our true positive rate is now around 66%, and our false positive rate is 38%. From a conservative investor's standpoint, it's reassuring that the false positive rate is lower, because it means that we'll be able to do a better job at avoiding bad loans, than if we funded everything. However, we'd only ever decide to fund 63% of total loans (true positive rate), so we'd immediately reject a good amount of loans.\n",
    "\n",
    "We can lower the false positive rate further by assigning a harsher penalty for misclassifying the negative class. While setting 'class_weight' to 'balanced' will automatically set a penalty based on the number of 1s and 0s in the column, we can also set a manual penalty. The penalty scikit-learn imposed for misclassifying a 0 would have been around 5.89 (since there are 5.89 times as many 1s as 0s).\n",
    "\n",
    "We can also specify a penalty manually if we want to adjust the rates more. To do this, pass in a dictionary of penalty values to the 'class_weight' parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# dictionary will impose penalty of 10 for misclassifying a 0, and 1 for misclassifying a 1\n",
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "# manually pass in the 'penalty' dictionary to 'class_weight'\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2356691747499471\n",
      "0.08708815672306322\n"
     ]
    }
   ],
   "source": [
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# number of true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# number of false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# number of true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning manual penalties lowered the false positive rate to 8%, and thus lowered our risk. This comes at the expense of true positive rate. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. Given that we're approaching this as a conservative investor, this strategy makes sense, but it's worth keeping in mind the tradeoffs.\n",
    "\n",
    "While we could tweak the penalties further, it's best to try a different (more complex) model, like random forest. Random forests can work with nonlinear data, and learn complex conditionals. Logistic regressions are only able to work with linear data. Training a random forest algorithm may enable us to get more accuracy due to columns that correlate nonlinearly with 'loan_status'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709304082434351\n",
      "0.9271593944790739\n"
     ]
    }
   ],
   "source": [
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# number of true positives\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# number of false negatives\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# number of true negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 8%, and a true positive rate of 23%. For a conservative investor, they will make money as long as the interest rate is high enough to offset the losses from 8% of borrowers defaulting, and that the pool of 23% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. We can still improve by:\n",
    "\n",
    "- tweaking the penalties further\n",
    "- try models other than a random forest and logistic regression\n",
    "- use some of the columns we discarded to generate better features\n",
    "- ensemble multiple models to get more accurate predictions\n",
    "- tune the parameters of the algorithm to achieve higher performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
